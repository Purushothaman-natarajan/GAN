{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fiU3kDLgyaA"
      },
      "source": [
        "Unsupervised machine learning for Image generation using GAN"
      ],
      "id": "4fiU3kDLgyaA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKM-Y9gMT_x3",
        "outputId": "50e38db9-c76b-4caf-f572-3c63b6ce7803"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "CKM-Y9gMT_x3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1ffa71d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers"
      ],
      "id": "f1ffa71d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05b3e887"
      },
      "source": [
        "Importing the dataset from the local directory"
      ],
      "id": "05b3e887"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bfa2fbb"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "from PIL import Image\n",
        "\n",
        "# Suppress the warning about palette images with transparency\n",
        "warnings.filterwarnings(\"ignore\", \"(Possibly )?corrupt EXIF data\", UserWarning)\n",
        "Image.warnings.simplefilter(\"ignore\", Image.DecompressionBombWarning)"
      ],
      "id": "1bfa2fbb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3ea32b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1443a8e3-8d4e-4126-b6a1-fa933eba10b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the array: (0,)\n"
          ]
        }
      ],
      "source": [
        "#path to my data directory\n",
        "main_folder = \"/content/drive/MyDrive/Colab Notebooks/Generative ML/Emoji Dataset\"\n",
        "# Desired dimensions and color mode for the images\n",
        "desired_dimension = (142, 107)\n",
        "desired_color_mode = \"RGBA\"\n",
        "\n",
        "# Initialize a list to store processed images\n",
        "processed_images = []\n",
        "\n",
        "# Traverse through subfolders and process images\n",
        "for root, _, files in os.walk(main_folder):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            image_path = os.path.join(root, file)\n",
        "            img = Image.open(image_path)\n",
        "            img = img.resize(desired_dimension)\n",
        "            img = img.convert(desired_color_mode)\n",
        "            img_array = np.array(img)\n",
        "            processed_images.append(img_array)\n",
        "\n",
        "# Convert the list of processed images into a numpy array\n",
        "images_array = np.array(processed_images)\n",
        "\n",
        "# Print the shape of the resulting array\n",
        "print(\"Shape of the array:\", images_array.shape)"
      ],
      "id": "b3ea32b4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1be8d9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4161364b-fe2d-40ce-d080-825123594f2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "type(images_array)"
      ],
      "id": "c1be8d9b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-UrqcicnfIa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "71db4c2e-b1b0-4b92-8317-35b77cd85293"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0239ffa78d2d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        }
      ],
      "source": [
        "images_array[0]"
      ],
      "id": "K-UrqcicnfIa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f642b9ef"
      },
      "outputs": [],
      "source": [
        "plt.imshow(images_array[0])"
      ],
      "id": "f642b9ef"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a587d422"
      },
      "outputs": [],
      "source": [
        "images_array= images_array.astype('float32')"
      ],
      "id": "a587d422"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "085474bf"
      },
      "outputs": [],
      "source": [
        "# Calculate the minimum and maximum values\n",
        "min_value = np.min(images_array)\n",
        "max_value = np.max(images_array)"
      ],
      "id": "085474bf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25e42f64"
      },
      "outputs": [],
      "source": [
        "normalized_array = 2 * (images_array - min_value) / (max_value - min_value) - 1\n",
        "\n",
        "print(normalized_array)"
      ],
      "id": "25e42f64"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4b87a50"
      },
      "outputs": [],
      "source": [
        "plt.imshow(normalized_array[0].squeeze(), cmap = 'brg')"
      ],
      "id": "e4b87a50"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "448f69dd"
      },
      "outputs": [],
      "source": [
        "buffer_size = 1664\n",
        "batch_size = 64"
      ],
      "id": "448f69dd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d7519d3"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(normalized_array).shuffle(buffer_size).batch(batch_size)"
      ],
      "id": "3d7519d3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d9b5595"
      },
      "outputs": [],
      "source": [
        "def generator_model():\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(128, input_dim = 200))\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "    model.add(layers.Dense(256))\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "    model.add(layers.Dense(512))\n",
        "    model.add(layers.ReLU())\n",
        "\n",
        "    model.add(layers.Dense(107 * 142 * 3, activation = 'sigmoid'))\n",
        "    model.add(layers.Reshape((107, 142, 3)))\n",
        "\n",
        "    return model"
      ],
      "id": "5d9b5595"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaf9b0e3"
      },
      "outputs": [],
      "source": [
        "generator = generator_model()\n",
        "generator.summary()"
      ],
      "id": "eaf9b0e3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f90c8ee"
      },
      "outputs": [],
      "source": [
        "noise = tf.random.normal([1, 200])\n",
        "generated_image = generator(noise, training = False)\n",
        "\n",
        "generated_image.shape"
      ],
      "id": "1f90c8ee"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7de7bb14"
      },
      "outputs": [],
      "source": [
        "plt.imshow(generated_image[0, :, :, 0], cmap = 'rainbow')"
      ],
      "id": "7de7bb14"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5783aaa5"
      },
      "outputs": [],
      "source": [
        "def discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Input(shape = (107, 142, 3)))\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    model.add(layers.Dense(512))\n",
        "    model.add(layers.LeakyReLU(0.2))\n",
        "\n",
        "    model.add(layers.Dense(256))\n",
        "    model.add(layers.LeakyReLU(0.2))\n",
        "\n",
        "    model.add(layers.Dense(128))\n",
        "    model.add(layers.LeakyReLU(0.2))\n",
        "\n",
        "    model.add(layers.Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "    return model"
      ],
      "id": "5783aaa5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eef10bc6"
      },
      "outputs": [],
      "source": [
        "discriminator = discriminator_model()\n",
        "discriminator.summary()"
      ],
      "id": "eef10bc6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30191991"
      },
      "outputs": [],
      "source": [
        "discriminator = discriminator_model()\n",
        "output = discriminator(generated_image)\n",
        "print (output)"
      ],
      "id": "30191991"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "452c2fd0"
      },
      "outputs": [],
      "source": [
        "bce = tf.keras.losses.BinaryCrossentropy()"
      ],
      "id": "452c2fd0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ad331a3"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "\n",
        "    real_loss = bce(tf.ones_like(real_output), real_output)\n",
        "\n",
        "    fake_loss = bce(tf.zeros_like(fake_output), fake_output)\n",
        "\n",
        "    total_loss = real_loss + fake_loss\n",
        "\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "\n",
        "    gen_loss = bce(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "    return gen_loss"
      ],
      "id": "7ad331a3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "752a4469"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001 )\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001 )"
      ],
      "id": "752a4469"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1e253a7"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer = generator_optimizer,\n",
        "                                 discriminator_optimizer = discriminator_optimizer,\n",
        "                                 generator = generator,\n",
        "                                 discriminator = discriminator)"
      ],
      "id": "b1e253a7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fe29c94"
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "noise_dim = 200\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "id": "6fe29c94"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aec9ef3"
      },
      "outputs": [],
      "source": [
        "def train_step(images):\n",
        "    noise = tf.random.normal([batch_size, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training = True)\n",
        "\n",
        "        real_output = discriminator(images, training = True)\n",
        "        fake_output = discriminator(generated_images, training = True)\n",
        "\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return (gen_loss, disc_loss, tf.reduce_mean(real_output), tf.reduce_mean(fake_output))"
      ],
      "id": "5aec9ef3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac231b13"
      },
      "outputs": [],
      "source": [
        "def generate_and_plot_images(model, epoch, test_input):\n",
        "\n",
        "    predictions = model(test_input, training = False)\n",
        "\n",
        "    fig = plt.figure(figsize = (8, 4))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        pred = (predictions[i, :, :, 0] + 1) * 127.5\n",
        "        pred = np.array(pred)\n",
        "        plt.imshow(pred.astype(np.uint8), cmap = 'rainbow')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.show()"
      ],
      "id": "ac231b13"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f5c0521"
      },
      "outputs": [],
      "source": [
        "def train(dataset, epochs):\n",
        "\n",
        "    gen_loss_list = []\n",
        "    disc_loss_list = []\n",
        "\n",
        "    real_score_list =[]\n",
        "    fake_score_list =[]\n",
        "    for epoch in (range(epochs)):\n",
        "        start = time.time()\n",
        "        num_batches = len(dataset)\n",
        "\n",
        "        print(f'Training started with  epoch {epoch + 1} with {num_batches} batches...')\n",
        "\n",
        "        total_gen_loss = 0\n",
        "        total_disc_loss = 0\n",
        "\n",
        "        for batch in dataset:\n",
        "            generator_loss, discriminator_loss, real_score, fake_score = train_step(batch)\n",
        "            total_gen_loss += generator_loss\n",
        "            total_disc_loss += discriminator_loss\n",
        "\n",
        "        mean_gen_loss = total_gen_loss / num_batches\n",
        "        mean_disc_loss = total_disc_loss / num_batches\n",
        "\n",
        "        print('Losses after epoch %5d: generator %.3f, discriminator %.3f, real_score %.2f%%, fake_score %.2f%%'  %\n",
        "              (epoch + 1, generator_loss, discriminator_loss, real_score * 100, fake_score * 100))\n",
        "\n",
        "        generate_and_plot_images(generator, epoch + 1, seed)\n",
        "\n",
        "        gen_loss_list.append(mean_gen_loss)\n",
        "        disc_loss_list.append(mean_disc_loss)\n",
        "        real_score_list.append(real_score)\n",
        "        fake_score_list.append(fake_score)\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "              checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "\n",
        "    return  gen_loss_list, disc_loss_list, real_score_list, fake_score_list"
      ],
      "id": "9f5c0521"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1253f5f8",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "gen_loss_epochs, disc_loss_epochs, real_score_list, fake_score_list = train(train_dataset, epochs = epochs)"
      ],
      "id": "1253f5f8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28393f53"
      },
      "outputs": [],
      "source": [
        "fig, (ax1,ax2) = plt.subplots(1, 2, figsize = (12, 8))\n",
        "\n",
        "ax1.plot(gen_loss_epochs, label = 'Generator loss', alpha = 0.5)\n",
        "ax1.plot(disc_loss_epochs, label = 'Discriminator loss', alpha = 0.5)\n",
        "ax1.legend()\n",
        "\n",
        "ax1.set_title('Training Losses')\n",
        "ax2.plot(real_score_list, label = 'Real score', alpha = 0.5)\n",
        "ax2.plot(fake_score_list, label = 'Fake score', alpha = 0.5)\n",
        "ax2.set_title('Accuracy Scores')\n",
        "\n",
        "ax2.legend()"
      ],
      "id": "28393f53"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}